import pandas as pd
import os 
import glob
import json
import random
import numpy as np

def open_archetype_file(filename):
    with open(filename, 'r') as archetype:
        read_archetype = []
        for line in archetype:
            line = line.split(',')
            if "\n" in line:
                line.remove("\n")
            read_archetype.append(list(map(float, line)))
    return read_archetype


def sample_triplets(parameters_path, archetype_path, private_count_path, triplets_dir, epsilon):
    # read archetypes from file
    archetype_files = glob.glob(os.path.join(archetype_path, 'archetype_*.txt'))

    archetypes = {}
    for file_index in range(0, len(archetype_files)):
        archetypes[file_index] = open_archetype_file(archetype_files[file_index])


    # read company_id domain from parameters.json
    with open(parameters_path, 'r') as f:
        parameters = json.load(f)

    company_id_domain = parameters['schema']['company_id']['values']

    # initialize data
    sampled_data = []

    # no. of archetypes
    n_arch = len(archetypes)

    '''
    using the taxi-ride distribution from the archetype information 
        generated by by step-0 and the private counts from step-1, and sampling
        triplets from the 3-way marginal;
    ''' 
    archetype_data_list = []
    max_records = parameters['runs']['epsilon' == epsilon]['max_records']
    overall_size = min(max_records, 2_000_000)
    max_rides_by_taxi = parameters['runs']['epsilon' == epsilon]['max_records_per_individual']
    first_taxi_id = parameters['schema']['taxi_id']['min'] # TODO: Need to get from parameters.json

    print("Sampling triplets and company_id")

    three_way_marginal_public = pd.read_csv(os.path.join(archetype_path, f'archetype_marginals.csv'))

    # get private counts of company ID for archetype
    private_counts_company = pd.read_csv(os.path.join(private_count_path, f"private_data_company_id_counts_{epsilon}.csv"))

    # get weights from private company counts
    private_counts_company_weights = private_counts_company['count'].tolist()

    # get ride/taxi counts per archetype
    archetype_names = list(range(n_arch))
    archetype_rides = []
    archetype_taxis = []
    for i in range(n_arch):
        archetype_rides.append(int(archetypes[i][4][1]))
        archetype_taxis.append(int(archetypes[i][4][0]))
    taxi_ride_df = pd.DataFrame({'archetype': archetype_names, 
                                    'n_taxis': archetype_taxis,
                                    'n_rides': archetype_rides})
    taxi_ride_df['scaled_n_rides'] = taxi_ride_df['n_rides'] / np.sum(taxi_ride_df['n_rides']) * overall_size
    taxi_ride_df['updated_rides_per_taxi'] = np.ceil(taxi_ride_df['n_rides'] / taxi_ride_df['n_taxis'])
    taxi_ride_df['updated_rides_per_taxi'] = np.clip(taxi_ride_df['updated_rides_per_taxi'], 1, max_rides_by_taxi)
    taxi_ride_df['updated_n_taxis'] = np.ceil(taxi_ride_df['scaled_n_rides'] / taxi_ride_df['updated_rides_per_taxi'])

    for i in range(n_arch):
        private_taxicount = taxi_ride_df.loc[taxi_ride_df['archetype'] == i]['updated_n_taxis'].item()
        private_ride_per_taxi = taxi_ride_df.loc[taxi_ride_df['archetype'] == i]['updated_rides_per_taxi'].item()

        print('archetype {0}: {1} taxis and {2} rides per taxi'.format(i, private_taxicount, private_ride_per_taxi))
        if private_taxicount == 0:
            continue

        three_way_marginal_public_cur_archetype = three_way_marginal_public[three_way_marginal_public['archetype']==i].reset_index()
        keys = list(zip(three_way_marginal_public_cur_archetype['shift'], three_way_marginal_public_cur_archetype['pickup_community_area'], three_way_marginal_public_cur_archetype['dropoff_community_area']))

        '''
        create 3-way marginal dictionary, sample from it, and generate company IDs
        '''
        three_way_marginal_dict = dict()
        for j in range(three_way_marginal_public_cur_archetype.shape[0]):
            three_way_marginal_dict[keys[j]] = three_way_marginal_public_cur_archetype.loc[j, '0']

        sampled_triplets = random.choices(population = list(three_way_marginal_dict.keys()), 
                                            weights = three_way_marginal_dict.values(), 
                                            k = int(private_taxicount * private_ride_per_taxi))

        shift, pickup, dropoff = map(list,zip(*sampled_triplets))
        
        # simulate company_id
        company_id = random.choices(population = company_id_domain, 
                                    weights = private_counts_company_weights,
                                    k = int(private_taxicount * private_ride_per_taxi))

        current_archetype_data = []
        current_archetype_data.append(shift)
        current_archetype_data.append(pickup)
        current_archetype_data.append(dropoff)
        current_archetype_data.append(company_id)

        # convert sampled data to correct orientation and add taxi IDs
        current_archetype_data = np.array(current_archetype_data).T
        taxi_ids = np.arange(first_taxi_id, first_taxi_id + private_taxicount)
        taxi_id_array = np.array([ [int(t)] * int(private_ride_per_taxi) for t in taxi_ids]).flatten()
        current_archetype_data = np.column_stack([taxi_id_array, current_archetype_data])
        archetype_data_list.append(current_archetype_data)
        first_taxi_id += private_taxicount

    # construct sampled data 
    sampled_data = np.vstack(archetype_data_list)

    # add taxi_ids to sampled_data
    sampled_data = pd.DataFrame(sampled_data, columns = ['taxi_id', 'shift', 'pickup_community_area',
                                                            'dropoff_community_area', 'company_id'])
    # sample data down to more manageable size 
    if sampled_data.shape[0] > max_records:
        sampled_data = sampled_data.sample(max_records, random_state = 0)


    # create dataframe from the sampled dataset list
    sampled_data_df = pd.DataFrame(sampled_data)

    # save sampled dataset as csv file
    sampled_data_df.to_csv(os.path.join(triplets_dir, f'sampled_triplet_{epsilon}.csv'), index = False)

    print("Sampling triplets finished: eps = {epsilon}")

